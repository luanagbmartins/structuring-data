{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2cbb17-eb8a-4547-a83b-3fd70cc46918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "import nmslib\n",
    "import os\n",
    "import json\n",
    "from keybert import KeyBERT\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from datetime import datetime\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "from similarity import Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df = pd.read_csv(\"data/jobs.csv\")\n",
    "jobs_df[\"title_description\"] = jobs_df.apply(\n",
    "    lambda x: x[\"title\"] + \". \" + x[\"description\"], axis=1\n",
    ")\n",
    "descriptions = jobs_df[\"title_description\"].values.tolist()\n",
    "len(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec090d1c-81d0-4167-8eac-68925e2cb48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.shuffle(descriptions)\n",
    "# split_point = int(len(descriptions) * 0.10)\n",
    "# set_01 = descriptions[:-split_point]\n",
    "# set_02 = descriptions[-split_point:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"indexed_docs\"\n",
    "\n",
    "now = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S-%f\")\n",
    "print(\"----- Strating at \" + now + \" -----\")\n",
    "out_dir = os.path.join(out_dir, now)\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_doc = [d.lower() for d in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = SentenceTransformer(\"stjiris/bert-large-portuguese-cased-legal-mlm-sts-v1.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_model = KeyBERT(model=nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_doc = [d.lower() for d in documents]\n",
    "\n",
    "params = {}\n",
    "params[\"stop_words\"] = stopwords.words(\"portuguese\")\n",
    "params[\"keyphrase_ngram_range\"] = (2, 2)\n",
    "params[\"top_n\"] = 10\n",
    "params[\"min_df\"] = int(len(lower_doc) * 0.005)\n",
    "params[\"use_maxsum\"] = False\n",
    "params[\"nr_candidates\"] = \"None\"\n",
    "params[\"use_mmr\"] = True\n",
    "params[\"diversity\"] = 0.2\n",
    "\n",
    "kw = kw_model.extract_keywords(lower_doc, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = []\n",
    "for k in kw:\n",
    "    local_embs = []\n",
    "    for key, val in k:\n",
    "        doc = nlp.encode(key)\n",
    "        local_embs.append(doc)\n",
    "    final_emb = np.array(local_embs).mean(axis=0)\n",
    "    try:\n",
    "        if final_emb.shape[0]:\n",
    "            embs.append(final_emb)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = nmslib.init(method=\"hnsw\", space=\"angulardist\")\n",
    "index.addDataPointBatch(embs)\n",
    "index.createIndex({\"post\": 2}, print_progress=True)\n",
    "\n",
    "print(datetime.now().strftime(\"%H-%M-%S-%f\") + \"----- Saving Index and Data -----\")\n",
    "data = []\n",
    "for doc, k in zip(lower_doc, kw):\n",
    "    data.append({\"doc\": doc, \"keys\": k})\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "index.saveIndex(os.path.join(out_dir, \"nms_index.index\"), save_data=True)\n",
    "print(\n",
    "    datetime.now().strftime(\"%H-%M-%S-%f\")\n",
    "    + \"----- Index Saved At: \"\n",
    "    + os.path.join(out_dir, \"nms_index.index\")\n",
    ")\n",
    "df.to_pickle(os.path.join(out_dir, \"docs.pkl\"))\n",
    "print(\n",
    "    datetime.now().strftime(\"%H-%M-%S-%f\")\n",
    "    + \"----- Docs Saved At: \"\n",
    "    + os.path.join(out_dir, \"docs.pkl\")\n",
    ")\n",
    "with open(os.path.join(out_dir, \"params.json\"), \"w\") as f:\n",
    "    json.dump(params, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
